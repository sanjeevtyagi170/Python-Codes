{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, sum\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+----+\n",
      "| id|salary|month|year|\n",
      "+---+------+-----+----+\n",
      "|  1|   100|    1|2022|\n",
      "|  1|   700|    2|2022|\n",
      "|  1|   600|    2|2022|\n",
      "|  2|  1000|    3|2022|\n",
      "|  2|  1100|    1|2022|\n",
      "|  3|   400|    1|2021|\n",
      "|  3|   500|    1|2021|\n",
      "+---+------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"sparkWindowFunctionsExample\").getOrCreate()\n",
    "data = [(1,100,1,2022),(1,700,2,2022),(1,600,2,2022),(2,1000,3,2022),(2,1100,1,2022),(3,400,1,2021),(3,500,1,2021)]\n",
    "df = spark.createDataFrame(data,schema=[\"id\",\"salary\",\"month\",\"year\"])\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+-------+\n",
      "|salary|month|year|ytd_sum|\n",
      "+------+-----+----+-------+\n",
      "|   400|    1|2021|    400|\n",
      "|   500|    1|2021|    900|\n",
      "|   100|    1|2022|    100|\n",
      "|  1100|    1|2022|   1200|\n",
      "|   600|    2|2022|    600|\n",
      "|   700|    2|2022|   1300|\n",
      "|  1000|    3|2022|   1000|\n",
      "+------+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_1=Window.partitionBy([\"year\",\"month\"]).orderBy(\"salary\")\n",
    "df=df.withColumn(\"ytd_sum\",sum(\"salary\").over(window_1)).drop(\"id\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+-------+\n",
      "|salary|month|year|ytd_sum|\n",
      "+------+-----+----+-------+\n",
      "|   400|    1|2021|    400|\n",
      "|   500|    1|2021|    900|\n",
      "|   100|    1|2022|    100|\n",
      "|  1100|    1|2022|   1200|\n",
      "|   600|    2|2022|    600|\n",
      "|   700|    2|2022|   1300|\n",
      "|  1000|    3|2022|   1000|\n",
      "+------+-----+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=spark.sql(\"\"\"SELECT\n",
    "    salary,\n",
    "    month,\n",
    "    year,\n",
    "    SUM(salary) OVER (PARTITION BY year,month ORDER BY salary) AS ytd_sum\n",
    "FROM df\n",
    "ORDER BY year, month;\"\"\")\n",
    "df2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
